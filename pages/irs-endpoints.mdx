# IRS Endpoints

Each IRS service is created by defining an **IRS endpoint**. The code that gets called when a new request is received at the endpoint depends on the way you configure your IRS endpoint. You can define multiple IRS services, each with its own endpoint.

## Creating an IRS Endpoint

You can use the `defineIRSEndpoint` function to define an IRS endpoint. This function takes an object with the following properties:

- `endpoint`: The server endpoint at which the intent recognition requests should be handled.
- `dataSource`: The data source from where the IRS data, intents data, and API keys data can be fetched. Check the [Data Sources](/data-sources) page to learn more.
- `enableAuth`: A boolean value indicating whether to enable authentication for the IRS endpoint. If set to `true`, the endpoint will require an API key to be provided in the request headers. The provided data source should be configured properly with reference to the API keys data. By default, it is set to `false`. Check the [Authentication](/authentication) page to learn more.
- `verbose`: If set to `true`, returns additional information in the response. May include usage information like the number of input and output tokens used, input and output characters, etc. By default, it is set to `false`.

```typescript
defineIRSEndpoint({
  endpoint: "irs",
  dataSource: irsDataSource,
  enableAuth: true,
  verbose: true,
  model: {
    primaryModel: {
      name: "gemini15flash",
      config: {
        temperature: 0.9,
      },
    },
    queryReformulationModel: {
      name: "gemini15flash",
      config: {
        temperature: 0.9,
      },
    },
    responseEvaluationModel: {
      name: "gemini15flash",
      config: {
        temperature: 0.9,
      },
    },
  },
});
```

## Configuring LLM Models

You can configure the LLM models to be used for the primary model, query reformulation model, and response evaluation model. The `model` property in the `defineIRSEndpoint` function takes an object with the following properties:

- `primaryModel`: The model to be used for intent recognition task.
- `queryReformulationModel`: The model to be used for reformulating the query to produce more accurate results.
- `responseEvaluationModel`: The model to be used for evaluating the response generated by the primary model.

Each of these properties takes an object with the following properties:

- `name`: Name of the LLM model to use.
- `config`: Configuration for the LLM model. This can include parameters like temperature, max output tokens, and safety settings.

### Supported LLM Models

Intento requires the use of LLM models that are capable of producing responses in JSON format.

By default, Intento uses the Gemini 15 Flash (`gemini15flash`) model provided by Google, for all tasks. This model performs extremely well on a wide range of tasks and is optimized for speed and accuracy.

Currently, you can only provide one of the following model names when configuring the IRS endpoint to use a specific model.

```
name: "gemini15flash" | "gemini15pro" | "gpt4o"
```

- `gemini15flash`: The Gemini 15 Flash model provided by Google. This model is optimized for speed and accuracy. Remember to set the `GOOGLE_GENAI_API_KEY` environment variable to use this model.
- `gemini15pro`: The Gemini 15 Pro model provided by Google. This model is optimized for generating high-quality text. Remember to set the `GOOGLE_GENAI_API_KEY` environment variable to use this model.
- `gpt4o`: The GPT-4o OpenAI model. This model is optimized for generating human-like text. Remember to set the `OPENAI_API_KEY` environment variable to use this model.
